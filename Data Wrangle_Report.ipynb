{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset that I have wrangled (and analyzed and visuzalized) is the tweet archive of Twitter user @dog_rates, also known as 'WeRateDogs'. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog.\n",
    "\n",
    "The twitter archive of this user contains 2356 rows of basic tweet data from November 2015 till August 2017. \n",
    "\n",
    "To enhance this basic tweet dataset, another file having the image predictions based on the tweet image was used. This was provided by Udacity and created by running each image in the WeRateDogs Twitter archive through a neural network that can classify breeds of dogs with a certain confidence interval. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather Twitter Archive CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following link provided by Udacity was used to download the csv file manually:\n",
    "\n",
    "https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv\n",
    "\n",
    "The csv file was imported and loaded using Pandas into a DataFrame named `twitter_archive`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather Tweet Image Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Predictions TSV file was downloaded programmatically using the Python's Requests library. The file was saved locally to 'image_predictions.tsv' file. Then this file was imported and loaded using Pandas into a DataFrame named `image_predictions`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather Data from Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Python Tweepy library, additional data was queries using the Twitter API. Each tweet_id in the `twitter_archive` was queried to access the entire data from Twitter API. Then the JSON data for each tweet was stored in a file called 'twitter_json.txt' file. This file was read using Pandas into a DataFrame named `tweets_data`. The columns in this DataFrame are 'tweet_id', 'retweet_count', 'favorite_count' and 'display_text_range'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was assesed both visually and programattically. Some of the issues were found visually, for example, the display text being cut off. While other issues were found programatically, for example, the missing data and the data types used for each column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> Visual Assessment</B>\n",
    "\n",
    "The following data issues were found by visual assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Quality: 'text' column of the `twitter_archive` was cut off. \n",
    "* Quality: Unnecessary / unwanted html tags in 'source' column of `twitter_archive`. \n",
    "* Tidiness: doggo, floofer, pupper and puppo columns, which are dog \"stages\", need to be merged into a new column named \"stage\".\n",
    "* Tidiness: Join the three DataFrames into one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> Programattic Assessment</B>\n",
    "\n",
    "The following data issues were found by programattic assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pandas info method was used to see the number of records, columns, missing records and data types of each columns in `twitter_archive`. \n",
    "* value_counts was used for 'name' column to see the dog names and their distribution. Some erroneous dog names were identified. \n",
    "* Pandas describe method was used to check the range of values, max and min values. This gave an idea of some unrealistic values. \n",
    "* value_counts was used for 'rating_numerator' and 'rating_denominator' columns to see the range and data distribution. Some unrealistic values were noted. \n",
    "\n",
    "The above methods were repeated for `image_predictions` and `tweet_info`. \n",
    "\n",
    "The following 12 <B>quality</B> issues were noted:\n",
    "\n",
    "1. Retweets exists in the table which leads to duplicate counts of tweets.\n",
    "\n",
    "\n",
    "2. Once retweets are removed from `twitter_archive`, drop the columns 'retweeted_status_id', 'retweeted_status_user_id' and 'retweeted_status_timestamp'.\n",
    "\n",
    "3. Not all tweet ids which exist in twitter_archive exist in image_predictions.\n",
    "\n",
    "4. Erroneous data types used in in_reply_to_status_id, in_reply_to_user_id, timestamp, retweeted_status_timestamp.\n",
    "\n",
    "5. 'rating_numerator': Very large values which seem unrealistic, for example, 960 and 1776.\n",
    "\n",
    "6. 'rating_denominator': Values other than 10 exist (values < 10 and values > 10).\n",
    "\n",
    "7. 'source' column: HTML tags appear which are unnecessary\n",
    "\n",
    "8. Erroneous / Incorrect dog names (like 'a', 'an', 'the') with lower case characters\n",
    "\n",
    "9. 'text' column: Contents are cut-off.\n",
    "\n",
    "10. \"Breed\" column to be added to `twitter_archive`. Fill the column from 'p1_conf' and 'p1_dog' columns from the `image_predictions` table. \n",
    "\n",
    "11. Multiple dog stages.\n",
    "\n",
    "12. Decimal dog ratings.\n",
    "\n",
    "\n",
    "The following 2 <B>tidiness</B> issues were noted:\n",
    "\n",
    "1. A new column named \"stage\" to be created in `twitter_archive`. Dog \"stage\" variable is stored in four individual columns: 'doggo', 'floofer', 'pupper', 'puppo'.\n",
    "\n",
    "2. Join 'retweet_count' and 'favorite_count' from `tweet_info` table to `twitter_archive`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copies of all the three DataFrames were created before doing any data cleaning activity. Define, Code and Test methodology was used to handle each data issue (quality and tidiness). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data was cleaned, the DataFrame with clean data `twitter_archive_clean` was stored as a CSV file named <B>'twitter_archive_master.csv'.</B>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
